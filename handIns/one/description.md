I created neural network with 2 hidden layers and 1 output layer. I also added a target network to stabilize the training. For selecting action I used epsilon-greedy strategy with decaying epsilon, so that the exploration rate is higher at the beginning, but as the learning progresses, the exploration rate gets lower. For loss function, I used mean square error function. 
Overall, my network performs decently. I tested it with various parameters and found out that it performs best with memory size 10000, batch size = 32, epsilon decay = 0.995 and learning rate = 0.0003. lower memory queue and higher learning rate would make it score well in the middle of the training, but towards the end it would start scoring significantly lower. With the current parameters, the average score from running 1000 games is around 400/500. 